{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duboko učenje\n",
    "\n",
    "### 3. laboratorijska vježba - Analiza klasifikacije sentimenta\n",
    "\n",
    "*Zagreb, 24.05.2020.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Izjava"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tekstovi zadataka se koriste samo u edukativne svrhe, te njihova prava još uvijek pripadaju autorima. Tekstovi zadatka preuzeti su sa [sljedeće poveznice](https://dlunizg.github.io/lab3/). Također, bilo kakve izmjene su isključivo radi estetike, i ne mijenjaju intelektualnog vlasnika na mene ili bilo kog tko uređuje ovu datoteku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sadržaj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Zadatak 1](#Zadatak-1)\n",
    "- [Zadatak 2](#Zadatak-2)\n",
    "- [Zadatak 3](#Zadatak-3)\n",
    "- [Zadatak 4](#Zadatak-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Učitavanje resursa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobrinite se da dođete u korijen projekta radi lakšeg adresiranja stvari:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"--IN_ROOT\" not in os.environ:\n",
    "    os.environ[\"--IN_ROOT\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/projekti/faks/DUBUCE/LAB3\n"
     ]
    }
   ],
   "source": [
    "if len(os.environ[\"--IN_ROOT\"]) == 0 or os.environ[\"--IN_ROOT\"] == \"false\":\n",
    "    %cd ..\n",
    "else:\n",
    "    print(os.getcwd())\n",
    "\n",
    "os.environ[\"--IN_ROOT\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bin.task_1 import Dataset, Vocabulary\n",
    "from bin.task_2 import Baseline\n",
    "from bin.task_3 import LSTM\n",
    "from bin.task_4 import RecurrentModel\n",
    "\n",
    "from util.embeddings import get_embedding_matrix, \\\n",
    "                            get_frequencies, \\\n",
    "                            pad_collate\n",
    "from util.metrics import evaluate\n",
    "from util.parameter_search import get_random_params\n",
    "from util.paths import *                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicijalizacija globalnih varijabli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pokretanje zadataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task_2 = False\n",
    "run_task_3 = False\n",
    "run_task_4_1 = False\n",
    "run_task_4_2 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vokabulari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = get_frequencies(TRAIN_CSV_PATH)\n",
    "\n",
    "data_vocab = Vocabulary(frequencies=word_frequencies,\n",
    "                        max_size=-1,\n",
    "                        min_freq=1,\n",
    "                        additional_tokens=[\"<PAD>\", \"<UNK>\"])\n",
    "label_vocab = Vocabulary(frequencies={\"positive\": 2, \"negative\": 1},\n",
    "                         max_size=-1,\n",
    "                         min_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skupovi podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset, val_dataset, te_dataset = [Dataset(csv_file_path=path,\n",
    "                                               data_vocab=data_vocab,\n",
    "                                               label_vocab=label_vocab)\n",
    "                                       for path in [TRAIN_CSV_PATH,\n",
    "                                                    VAL_CSV_PATH,\n",
    "                                                    TEST_CSV_PATH]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding matrica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter `separate_unk` određuje hoćemo li token \"<UNK>\" ostaviti da ima vrijednost definiranu zadanom vrijednošću (ako je postavljen na `False`), ili ćemo ga postaviti na 1-vektor (ako je postavljen na `True`). Podrazumijevana vrijednost je `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = get_embedding_matrix(vocabulary=data_vocab,\n",
    "                                        file_path=EMBEDDINGS_PATH,\n",
    "                                        separate_unk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadatak 1\n",
    "\n",
    "### Učitavanje podataka\n",
    "*25% bodova*\n",
    "\n",
    "#### [Zadatak 2 ->](#Zadatak-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Razred `Vocab`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kao što smo spomenuli na predavanjima, jedan od hiperparametara svakog modela obrade prirodnog jezika je odabir veličine vokabulara, tj., broja riječi koje ćemo reprezentirati u našem modelu. Procedura odabira se u praksi provodi u nekoj vrsti `Vocab` razreda, pri izgradnji rječnika `itos` (index-to-string) i `stoi` (string-to-index)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svakom ulaznom polju našeg skupa podataka pridodjeljujemo jedan vokabular. Vaša implementacija vokabulara se treba izgraditi temeljem rječnika frekvencija za neko polje. Rječnik frekvencija kao ključeve sadrži sve tokene koji su se pojavili u tom polju, dok su vrijednosti broj pojavljivanja svakog tokena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Također, vaša implementacija razreda Vocab mora primati iduće parametre:\n",
    "\n",
    " - `max_size`: maksimalni broj tokena koji se sprema u vokabular (uključuje i posebne znakove). $-1$ označava da se spremaju svi tokeni.\n",
    " - `min_freq`: minimalna frekvencija koju token mora imati da bi ga se spremilo u vokabular ($\\ge$). Posebni znakovi ne prolaze ovu provjeru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bitno**: vokabular se izgrađuje samo na train skupu podataka. Jednom izgrađeni vokabular na train skupu postavljate kao vokabular testnog i validacijskog skupa podataka. Ovaj pristup se smatra najkorektniji u analizi teksta jer kroz izgradnju vokabulara na testnom i validacijskom skupu imamo curenje informacija u treniranje modela. Primjerice – u realnoj situaciji gdje deployate vaš model nije vjerojatno da će vaš model svaku viđenu riječ imati u vokabularu. Prema tome, ovakav način evaluacije, iako stroži, je realističniji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odgovor**:\n",
    "\n",
    "Ovo možemo pokazati na globalnim vokabularima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> <PAD>\n",
      "1 -> <UNK>\n",
      "2 -> the\n",
      "3 -> a\n",
      "4 -> and\n",
      "\n",
      "<PAD>\t-> 0\n",
      "<UNK>\t-> 1\n",
      "the\t-> 2\n",
      "a\t-> 3\n",
      "and\t-> 4\n"
     ]
    }
   ],
   "source": [
    "for key, value in list(data_vocab.itos.items())[:5]:\n",
    "    print(f\"{key} -> {value}\")\n",
    "    \n",
    "print()\n",
    "\n",
    "for key, value in list(data_vocab.stoi.items())[:5]:\n",
    "    print(f\"{key}\\t-> {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> positive\n",
      "1 -> negative\n",
      "\n",
      "positive -> 0\n",
      "negative -> 1\n"
     ]
    }
   ],
   "source": [
    "for key, value in list(label_vocab.itos.items()):\n",
    "    print(f\"{key} -> {value}\")\n",
    "    \n",
    "print()\n",
    "\n",
    "for key, value in list(label_vocab.stoi.items()):\n",
    "    print(f\"{key} -> {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Učitavanje vektorskih reprezentacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U okviru laboratorijske vježbe, uz skup podataka, dobiti ćete i podskup prednaučenih reprezentacija riječi [GloVe](https://nlp.stanford.edu/projects/glove/). Ove vektorske reprezentacije možete preuzeti [ovdje](https://drive.google.com/file/d/12mA5QEN4nFcxfEzOS8Nqj5afOmkuclc7/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaš zadatak je implementirati funkciju koja će za zadani vokabular (iterable stringova) generirati embedding matricu. Vaša funkcija treba podržavati dva načina genriranja embedding matrice: nasumična inicijalizacija iz standardne normalne razdiobe ($\\mathbb{N}(0,1)$) i učitavanjem iz datoteke. Pri učitavanju iz datoteke, ako ne pronađete vektorsku reprezentaciju za neku riječ, inicijalizirajte ju normalno. Vektorsku reprezentaciju za znak punjenja (na indeksu $0$) morate inicijalizirati na vektor nula. Jednostavan način na koji možete implementirati ovo učitavanje je da inicijalirate matricu iz standardne normalne razdiobe, a potom prebrišete inicijalnu reprezentaciju u retku za svaku riječ koju učitate. Bitno: Pripazite da redoslijed vektorskih reprezentacija u matrici odgovara redoslijedu riječi u vokabularu! Npr., na indeksu 0 mora biti reprezentacija za posebni znak punjenja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odgovor**:\n",
    "\n",
    "Embedding matricu smo napravili, i ona je pohranjena kao globalna varijabla u `embedding_matrix`. Nju predajemo modelima koji potom stvaraju `torch.nn.Embedding` objekt i koriste ju prilikom rada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<br>Dimenzije te matrice su **(14806, 300)**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<br>Dimenzije te matrice su **{embedding_matrix.shape}**.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nadjačavanje metoda `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da bi naša implementacija razreda `Dataset` bila potpuna, potrebno je nadjačati `__getitem__` metodu koja omogućava indeksiranje razreda. Za potrebe vježbe, ta metoda treba vraćati numerikalizirani text i labelu referencirane instance. Također, dovoljno je napraviti da se numerikalizacija radi “on-the-fly”, i nije ju nužno cachirati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odgovor**:\n",
    "\n",
    "Prikažimo primjer rada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data, t1_label = tr_dataset.instances[3]\n",
    "t1_id_data, t1_id_label = tr_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podatci: ['yet', 'the', 'act', 'is', 'still', 'charming', 'here']\n",
      "Oznaka: positive\n"
     ]
    }
   ],
   "source": [
    "print(f\"Podatci: {t1_data}\")\n",
    "print(f\"Oznaka: {t1_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifikatorski podatci: tensor([189,   2, 674,   7, 129, 348, 143])\n",
      "Identifikatorska oznaka: 0\n"
     ]
    }
   ],
   "source": [
    "t1_id_data, t1_id_label = tr_dataset[3]\n",
    "print(f\"Identifikatorski podatci: {t1_id_data}\")\n",
    "print(f\"Identifikatorska oznaka: {t1_id_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementacija batchiranja podataka: `collate` funkcija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skoro smo spremni za implementaciju modela – jedino što je preostalo je implementacija pretvorbi niza elemenata u batch podataka. Ovdje se ponovno susrećemo s problemom varijabilnosti dimenzije."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorchev `torch.utils.data.DataLoader` pri spremanju podataka u batcheve u svojoj defaultnoj implementaciji collate funkcije očekuje da su elementi batcha jednake duljine. Ovo u tekstu nije slučaj, te u praksi moramo implementirati vlastitu collate funkciju."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bitno**: u vašoj collate funkciji vraćajte i duljine originalnih instanci (koje nisu nadopunjene). Duljine će nam poslužiti pri implementaciji naših modela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadatak naše collate funkcije biti će nadopuniti duljine instanci znakom punjenja do duljine najdulje instance u batchu. Za ovo, pogledajte funkciju from `torch.nn.utils.rnn.pad_sequence`. Primjetite da vaša implementacija collate funkcije mora znati koji se indeks koristi kao znak punjenja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odgovor**:\n",
    "\n",
    "Prikažimo primjer rada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset=tr_dataset,\n",
    "                                         batch_size=2,\n",
    "                                         shuffle=False,\n",
    "                                         collate_fn=pad_collate)\n",
    "texts, labels, lengths = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podatci:\n",
      "tensor([[   2,  554,    7, 2872,    6,   22,    2, 2873, 1236,    8,   96, 4800,\n",
      "            4,   10,   72,    8,  242,    6,   75,    3, 3576,   56, 3577,   34,\n",
      "         2022, 2874, 7123, 3578, 7124,   42,  779, 7125,    0,    0],\n",
      "        [   2, 2875, 2023, 4801,    5,    2, 3579,    5,    2, 2876, 4802,    7,\n",
      "           40,  829,   10,    3, 4803,    5,  627,   62,   27, 2877, 2024, 4804,\n",
      "          962,  715,    8, 7126,  555,    5, 7127, 4805,    8, 7128]])\n",
      "\n",
      "Oznake:\n",
      "tensor([0, 0])\n",
      "\n",
      "Duljine: \n",
      "tensor([32, 34])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Podatci:\\n{texts}\\n\")\n",
    "print(f\"Oznake:\\n{labels}\\n\")\n",
    "print(f\"Duljine: \\n{lengths}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadatak 2\n",
    "\n",
    "### Implementacija baseline modela\n",
    "*25% bodova*\n",
    "\n",
    "#### [<- Zadatak 1](#Zadatak-1) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [Zadatak 3 ->](#Zadatak-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaš zadatak u laboratorijskoj vježbi je implementirati model koji će koristiti sažimanje usrednjavanjem (*eng. mean pooling*) kako bi eliminirao problematičnu varijabilnu dimenziju. Pri primjeni sažimanja usrednjavanjem odmah eliminirajte cijelu vremensku dimenziju (tzv. *okno* je veličine $T$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osnovni model koji implementirate mora izgledati ovako:\n",
    "\n",
    "```\n",
    "avg_pool() -> fc(300, 150) -> ReLU() -> fc(150, 150) -> ReLU() -> fc(150,1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kao gubitak predlažemo da koristite `BCEWithLogitsLoss`, u kojem slučaju ne morate primjeniti sigmoidu na izlaznim logitima. Alternativno, možete staviti da vam je izlazna dimenzionalnost broj klasa te koristiti gubitak unakrsne entropije. Oba pristupa su korištena u praksi ovisno o osobnim preferencama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kao algoritam optimizacije koristite [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementirajte metrike praćenja performansi modela. Osim gubitka na skupu podataka, zanimaju nas preciznost (*eng. accuracy*), [f1 mjera](https://en.wikipedia.org/wiki/F1_score) i matrica zabune (eng. *confusion matrix*). Nakon svake epohe ispišite performanse modela po svim metrikama na skupu za validaciju, a nakon zadnje epohe ispišite performanse modela na skupu za testiranje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postavljanje random seeda za pytorch operacije na CPU se vrši sa `torch.manual_seed(seed)`, dok istu stvar napravite i ukoliko u vašem kodu koristite numpy s `np.random.seed(seed)`. Ako pokrećete kod na grafičkoj kartici, obratite pozornost na upozorenja [ovdje](https://pytorch.org/docs/stable/notes/randomness.html#cudnn). Povratne neuronske mreže su CUDNN optimizirane, te je moguće da reproducibilnost nije 100% osigurana osim ako ne pratite upute s poveznice nauštrb brzine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bitno**: Dok god rezultati vašeg koda ne variraju iznimno puno (za različita pokretanja), točne izlazne brojke ne moraju biti savršeno jednake. Kako bi provjerili varijancu (tj. stabilnost) vašeg modela, vaš konačni model pokrenite barem 5 puta s istim hiperparametrima, ali različitim seedom. Zapišite (u excel tablicu, word dokument ili slično) rezultate izvođenja (sve navedene metrike) za svaki seed. U komentar dodajte i hiperparametre za pokretanje modela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odgovor**:\n",
    "\n",
    "Konstruirajmo modele i istrenirajmo ih $5$ puta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<br>Zastavica za pokretanje zadatka 2 je postavljena na `False` pa zadatak nije pokrenut."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if run_task_2:\n",
    "    for i in range(5):\n",
    "        t2_seed = np.random.randint(0, 2 ** 32)\n",
    "        t2_save_folder = os.path.join(DEFAULT_SAVE_TASK2, f\"run-{i + 1}\")\n",
    "\n",
    "        torch.manual_seed(t2_seed)\n",
    "        np.random.seed(t2_seed)\n",
    "\n",
    "        t2_model = Baseline(embedding_matrix=embedding_matrix,\n",
    "                            units=(300, 150, 150, 1),\n",
    "                            loss=torch.nn.BCEWithLogitsLoss(),\n",
    "                            freeze_embedding=False)\n",
    "        t2_model.fit(dataset=tr_dataset,\n",
    "                     validation_dataset=val_dataset,\n",
    "                     n_epochs=5,\n",
    "                     learning_rate=1e-4,\n",
    "                     batch_size=10,\n",
    "                     save_folder=t2_save_folder,\n",
    "                     verbose=1)\n",
    "\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    display(Markdown(\"<br>Zastavica za pokretanje zadatka 2 je postavljena na `False` \"\n",
    "                     \"pa zadatak nije pokrenut.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadatak 3\n",
    "\n",
    "### Implementacija povratne neuronske mreže\n",
    "*25% bodova*\n",
    "\n",
    "#### [<- Zadatak 2](#Zadatak-2) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [Zadatak 4 ->](#Zadatak-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakon što ste uspješno implementirali vaš baseline model, vrijeme je da isprobamo neki model baziran na povratnim neuronskim mrežama. Vaš zadatak je implementirati osnovni model povratne neuronske meže po izboru. Na izboru su vam iduće ćelije: [“Vanilla” RNN](https://pytorch.org/docs/master/generated/torch.nn.RNN.html#torch.nn.RNN), [GRU](https://pytorch.org/docs/master/generated/torch.nn.GRU.html#torch.nn.GRU), [LSTM](https://pytorch.org/docs/master/generated/torch.nn.LSTM.html#torch.nn.LSTM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za odabrani model, detaljno pročitajte njegovu dokumentaciju. U nastavku ćemo vam samo skrenuti pozornost na nekoliko bitnih detalja:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Svaka RNN mreža kao izlaz svoje `forward` metode vraća\n",
    "   - niz skrivenih stanja posljednjeg sloja\n",
    "   - skriveno stanje (tj., skrivena stanja u slučaju LSTMa) za sve slojeve zadnjeg vremenskog koraka.\n",
    "  Kao ulaz u dekoder obično želite staviti skriveno stanje iz zadnjeg sloja u zadnjem vremenskom koraku. Kod LSTMa, to je `h` komponenta dualnog `(h, c)` skrivenog stanja.\n",
    "- Radi brzine, RNN mreže preferiraju inpute u `time-first` formatu (budući da je brže iterirati po prvoj dimenziji tenzora). Transponirajte ulaze prije nego ih šaljete RNN ćeliji.\n",
    "- Tenzori koji su ulaz u RNN ćelije se često [“pakiraju”](https://pytorch.org/docs/master/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence). Pakiranje je zapis tenzora kojemu su pridružene stvarne duljine svakog elementa u batchu. Ako koristite pakiranje, RNN mreža se neće odmatati za vremenske korake koji sadrže padding u elementima batcha. Ovdje osim efikasnosti možete dobiti i na preciznosti, ali ovaj dio nije nužan dio vaše implementacije.\n",
    "- Implementirajte [gradient clipping](https://pytorch.org/docs/master/generated/torch.nn.utils.clip_grad_norm_.html#torch.nn.utils.clip_grad_norm_) prije optimizacijskog koraka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osnovni model vaše odabrane RNN ćelije treba izgledati ovako:\n",
    "\n",
    "```\n",
    "rnn(150) -> rnn(150) -> fc(150, 150) -> ReLU() -> fc(150,1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaš osnovni model RNN ćelije bi trebao biti jednosmjeran i imati dva sloja. Za višeslojni RNN iskoristite argument `num_layers` pri konstrukciji RNN mreže."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odgovor**:\n",
    "\n",
    "Konstruirajmo modele i istrenirajmo ih $5$ puta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<br>Zastavica za pokretanje zadatka 3 je postavljena na `False` pa zadatak nije pokrenut."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if run_task_3:\n",
    "    for i in range(5):\n",
    "        t3_seed = np.random.randint(0, 2 ** 32)\n",
    "        t3_save_folder = os.path.join(DEFAULT_SAVE_TASK3, f\"run-{i + 1}\")\n",
    "\n",
    "        torch.manual_seed(t3_seed)\n",
    "        np.random.seed(t3_seed)\n",
    "\n",
    "        t3_model = LSTM(embedding_matrix=embedding_matrix,\n",
    "                        rnn_units=(300, 150, 150),\n",
    "                        fc_units=(150, 150, 1),\n",
    "                        loss=torch.nn.BCEWithLogitsLoss(),\n",
    "                        freeze_embedding=False)\n",
    "        t3_model.fit(dataset=tr_dataset,\n",
    "                     validation_dataset=val_dataset,\n",
    "                     n_epochs=5,\n",
    "                     learning_rate=1e-4,\n",
    "                     batch_size=10,\n",
    "                     gradient_clipping=0.25,\n",
    "                     save_folder=t3_save_folder,\n",
    "                     verbose=1)\n",
    "\n",
    "        print(\"\\n\")\n",
    "else:\n",
    "    display(Markdown(\"<br>Zastavica za pokretanje zadatka 3 je postavljena na `False` \"\n",
    "                     \"pa zadatak nije pokrenut.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadatak 4\n",
    "\n",
    "### Usporedba modela i pretraga hiperparametara\n",
    "*25% bodova*\n",
    "\n",
    "#### [<- Zadatak 3](#Zadatak-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kao što vidimo, naše incijalne implementacije modela su dosta slične po preciznosti. Kako rezultati pokretanja modela za jedan skup hiperparametara mogu biti čista sreća ili nesreća, u ovom dijelu laboratorijske vježbe ćemo implementirati iscrpnu pretragu kroz varijante modela i njihove hiperparametre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usporedba RNN ćelija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neovisno o tome koju RNN ćeliju ste odabrali u trećem zadatku, proširite vaš kod na način da vrsta RNN ćelije bude argument. Pokrenite vaš kod za preostale vrste RNN ćelija i zapišite rezultate. Je li neka ćelija očiti pobjednik? Je li neka ćelija očiti gubitnik?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponovite ovu usporedbu uz izmjenu hiperparametara povratnih neuronskih mreža. Idući hiperparametri povratnih neuronskih mreža su nam interesantni:\n",
    "\n",
    "- `hidden_size`\n",
    "- `num_layers`\n",
    "- `dropout`: primjenjen između uzastopnih slojeva RNNa (funkcionira samo za $2$+ slojeva)\n",
    "- `bidirectional`: dimenzionalnost izlaza dvosmjerne rnn ćelije je dvostruka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isprobajte barem $3$ različite vrijednosti za svaki hiperparametar (osim bidirectional, koji ima samo dvije vrijednosti). Način na koji ćete kombinirati te vrijednosti je potpuno na vama (iscrpna rešetkasta pretraga je vremenski previše zahtjevna). Pokrenite svaku vrstu ćelije za svaku kombinaciju hiperparametara i zapišite rezultate (relevantne metrike). Nemojte se bojati raditi agresivne izmjene u vrijednostima hiperparametara (male izmjene vam neće dati puno informacija). Primjećujete li da neki hiperparametar bitno utječe na performanse ćelija? Koji?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odgovor**:\n",
    "\n",
    "Odabrat ćemo $3$ različite vrijednosti za svaki hiperparametar za svaku mrežu, te potom na LSTMu isprobati što se događa kad mreža ima dvosmjerne izlaze: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4_1_range_dict = {\n",
    "    \"hidden_size\": (75, 601),\n",
    "    \"num_layers\": (2, 9),\n",
    "    \"dropout\": (0.2, 0.75)\n",
    "}\n",
    "\n",
    "t4_1_params_list = get_random_params(range_dict=t4_1_range_dict,\n",
    "                                     amount=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sad možemo i prikazati te vrijednosti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 480\n",
      "num_layers:  6\n",
      "dropout:     0.24\n",
      "\n",
      "hidden_size: 188\n",
      "num_layers:  8\n",
      "dropout:     0.59\n",
      "\n",
      "hidden_size: 306\n",
      "num_layers:  5\n",
      "dropout:     0.28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in t4_1_params_list:\n",
    "    print(f\"hidden_size: {param['hidden_size']}\\n\"\n",
    "          f\"num_layers:  {param['num_layers']}\\n\"\n",
    "          f\"dropout:     {param['dropout']:.02f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izvrtimo ovo za svaki tip povratne mreže:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<br>Zastavica za pokretanje 1. dijela 4. zadatka je postavljena na `False` pa zadatak nije pokrenut."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if run_task_4_1:\n",
    "    t4_seed = np.random.randint(0, 2 ** 32)\n",
    "    \n",
    "    torch.manual_seed(t4_seed)\n",
    "    np.random.seed(t4_seed)\n",
    "    \n",
    "    for rnn_type in [\"rnn\", \"lstm\", \"gru\"]:\n",
    "        for i, hyperparameters in enumerate(t4_1_params_list):\n",
    "            t4_save_folder = os.path.join(DEFAULT_SAVE_TASK4, f\"{rnn_type}_run-{i + 1}\")\n",
    "            \n",
    "            t4_model = RecurrentModel(embedding_matrix=embedding_matrix,\n",
    "                                      rnn_type=rnn_type,\n",
    "                                      rnn_hidden_size=hyperparameters[\"hidden_size\"],\n",
    "                                      rnn_num_layers=hyperparameters[\"num_layers\"],\n",
    "                                      rnn_dropout=hyperparameters[\"dropout\"],\n",
    "                                      rnn_bidirectional=False,\n",
    "                                      fc_activation_function=torch.relu,\n",
    "                                      fc_units=(150, 150, 1),\n",
    "                                      loss=torch.nn.BCEWithLogitsLoss(),\n",
    "                                      freeze_embedding=False)\n",
    "            t4_model.fit(dataset=tr_dataset,\n",
    "                         validation_dataset=val_dataset,\n",
    "                         n_epochs=5,\n",
    "                         optimizer=torch.optim.Adam,\n",
    "                         learning_rate=1e-4,\n",
    "                         batch_size=10,\n",
    "                         gradient_clipping=0.25,\n",
    "                         save_folder=t4_save_folder,\n",
    "                         additional_params=hyperparameters,\n",
    "                         verbose=1)\n",
    "\n",
    "            print(\"\\n\")\n",
    "            \n",
    "    # TODO IZVRTI ZA NAJBOLJI RECURRENT MODEL\n",
    "else:\n",
    "    display(Markdown(\"<br>Zastavica za pokretanje 1. dijela 4. zadatka je postavljena na `False` \"\n",
    "                     \"pa zadatak nije pokrenut.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizacija hiperparametara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probajte pokrenuti povratne neuronske mreže za najbolji set hiperparametara bez da koristite prednaučene vektorske reprezentacije. Probajte isto za vaš baseline model. Koji model više “pati” od gubitka prednaučenih reprezentacija?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ulazne vektorske reprezentacije su jedan jako bitan hiperparametar, za koji u okviru laboratorijske vježbe imamo samo dvije vrijednosti – koristimo li ih ili ne. U analizi teksta su ulazne vektorske reprezentacije veoma velik dio uspješnosti algoritma. U ovom dijelu laboratorijske vježbe trebate odabrati barem $5$ od idućih hiperparametara te provjeriti kako modeli funkcioniraju za njihove izmjene. Ako hiperparametar utječe i na baseline model, kao i povratnu neuronsku mrežu, pokrenite eksperimente na oba modela. Za ćeliju povratne neuronske mreže odaberite onu koja ostvaruje (po vama) bolje rezultate na prošlom dijelu vježbe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za hiperparametre označene s nekim brojem, odaberite samo jedan od onih s istim brojem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametri:\n",
    "\n",
    "- Veličina vokabulara V$^1$\n",
    "- Minimalna frekvencija riječi min_freq$^1$\n",
    "- Stopa učenja$^2$\n",
    "- Veličina batcha$^2$\n",
    "- Dropout\n",
    "- Broj slojeva\n",
    "- Dimenzionalnost skrivenih slojeva\n",
    "- Optimizacijski algoritam (probajte nešto osim Adama)\n",
    "- Funkcija nelinearnosti (u potpuno povezanim slojevima)\n",
    "- Iznos na koji se podrezuju vrijednosti gradijenata\n",
    "- Vrsta sažimanja (Baseline)\n",
    "- Zamrzavanje ulaznih vektorskih reprezentacije (argument freeze funkcije from_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odgovor**:\n",
    "\n",
    "Odabrat ćemo sljedeći skup parametara:\n",
    "\n",
    "- Veličina vokabulara (u rangu $\\left[ 100, 16000 \\right]$)\n",
    "- Veličina batcha (u rangu $\\left[ 1, 128 \\right]$)\n",
    "- Dropout (u rangu $\\left[ 0, 0.75 \\right]$)\n",
    "- Dimenzionalnost skrivenih slojeva (u rangu $\\left[ 75, 600 \\right]$)\n",
    "- Zamrzavanje ulaznih vektorskih reprezentacija\n",
    "\n",
    "i napraviti $5$ uređenih četvorki uz zamrzavanje učenja embeddinga. Na kraju ćemo testirati što se događa ako dopustimo mreži da nauči embeddinge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4_2_range_dict = {\n",
    "    \"vocab_max_size\": (100, 16001),\n",
    "    \"batch_size\": (1, 129),\n",
    "    \"dropout\": (0., 0.75),\n",
    "    \"hidden_size\": (75, 601)\n",
    "}\n",
    "\n",
    "t4_2_params_list = get_random_params(range_dict=t4_2_range_dict,\n",
    "                                     amount=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kao i prije, možemo prikazati ove vrijednosti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_size:    15168\n",
      "batch_size:  118\n",
      "dropout:     0.49\n",
      "hidden_size: 278\n",
      "\n",
      "max_size:    15928\n",
      "batch_size:  6\n",
      "dropout:     0.39\n",
      "hidden_size: 263\n",
      "\n",
      "max_size:    10517\n",
      "batch_size:  75\n",
      "dropout:     0.28\n",
      "hidden_size: 254\n",
      "\n",
      "max_size:    10754\n",
      "batch_size:  84\n",
      "dropout:     0.26\n",
      "hidden_size: 215\n",
      "\n",
      "max_size:    9185\n",
      "batch_size:  92\n",
      "dropout:     0.03\n",
      "hidden_size: 265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in t4_2_params_list:\n",
    "    print(f\"max_size:    {param['vocab_max_size']}\\n\"\n",
    "          f\"batch_size:  {param['batch_size']}\\n\"\n",
    "          f\"dropout:     {param['dropout']:.02f}\\n\"\n",
    "          f\"hidden_size: {param['hidden_size']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<br>Zastavica za pokretanje 2. dijela 4. zadatka je postavljena na `False` pa zadatak nije pokrenut."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if run_task_4_2:\n",
    "    t4_seed = np.random.randint(0, 2 ** 32)\n",
    "    \n",
    "    torch.manual_seed(t4_seed)\n",
    "    np.random.seed(t4_seed)\n",
    "    \n",
    "    for rnn_type in [\"rnn\", \"lstm\", \"gru\"]:\n",
    "        for i, hyperparameters in enumerate(t4_2_params_list):\n",
    "            t4_data_vocab = Vocabulary(frequencies=word_frequencies,\n",
    "                                       max_size=hyperparameters[\"vocab_max_size\"],\n",
    "                                       min_freq=1,\n",
    "                                       additional_tokens=[\"<PAD>\", \"<UNK>\"])\n",
    "            t4_tr_dataset, t4_val_dataset, t4_te_dataset = [Dataset(csv_file_path=path,\n",
    "                                                                    data_vocab=t4_data_vocab,\n",
    "                                                                    label_vocab=label_vocab)\n",
    "                                                            for path in [TRAIN_CSV_PATH,\n",
    "                                                                         VAL_CSV_PATH,\n",
    "                                                                         TEST_CSV_PATH]]\n",
    "            t4_embedding_matrix = get_embedding_matrix(vocabulary=t4_data_vocab,\n",
    "                                                       file_path=None,\n",
    "                                                       separate_unk=True)\n",
    "            \n",
    "            t4_save_folder = os.path.join(DEFAULT_SAVE_TASK4, f\"{rnn_type}_run-{i + 1}_part-2\")\n",
    "            \n",
    "            t4_model = RecurrentModel(embedding_matrix=t4_embedding_matrix,\n",
    "                                      rnn_type=rnn_type,\n",
    "                                      rnn_hidden_size=hyperparameters[\"hidden_size\"],\n",
    "                                      rnn_num_layers=2,\n",
    "                                      rnn_dropout=hyperparameters[\"dropout\"],\n",
    "                                      rnn_bidirectional=False,\n",
    "                                      fc_activation_function=torch.relu,\n",
    "                                      fc_units=(150, 150, 1),\n",
    "                                      loss=torch.nn.BCEWithLogitsLoss(),\n",
    "                                      freeze_embedding=True)\n",
    "            t4_model.fit(dataset=tr_dataset,\n",
    "                         validation_dataset=val_dataset,\n",
    "                         n_epochs=5,\n",
    "                         optimizer=torch.optim.Adam,\n",
    "                         learning_rate=1e-4,\n",
    "                         batch_size=hyperparameters[\"batch_size\"],\n",
    "                         gradient_clipping=0.25,\n",
    "                         save_folder=t4_save_folder,\n",
    "                         additional_params=hyperparameters,\n",
    "                         verbose=1)\n",
    "\n",
    "            print(\"\\n\")\n",
    "            \n",
    "    # TODO IZVRTI UZ UČENJE EMBEDDINGA\n",
    "else:\n",
    "    display(Markdown(\"<br>Zastavica za pokretanje 2. dijela 4. zadatka je postavljena na `False` \"\n",
    "                     \"pa zadatak nije pokrenut.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
